# [MNIST, FASHION_MNIST, or two others]
# TODO
dataset: FASHION_MNIST

learning_rate_auto_encoder: 0.01
learning_rate_classifier: 0.01

# Options: [MSE, cross_entropy]
loss_function_auto_encoder: cross_entropy
loss_function_classifier: cross_entropy

# Options: [SGD, Adam]
optimizer: Adam

# TODO add NN architecture, neuron count, activation functions etc.
architecture:
  - neurons: 10
    activation_funtion: relu

  - neurons: 10
    activation_funtion: sigmoid

latent_vector_size: 4

epochs_auto_encoder: 10
epochs_classifier: 10

batch_size: 64

# How we should split the dataset. Unlabelled vs. labelled data ratio
split_ratio: 0.8

# How we divide D2 (labelled data) into training, validation and test sets
# TODO look over these, since Keras load() functions already splits
training_ratio: 0.7
validation_ratio: 0.2
testing_ratio: 0.1

# Whether or not to freeze the weights of the encoder module when using it in
# the classifier.
freeze: True

# The number of autoencoder reconstructions (and corresponding input images)
# to display at the end of the run.
auto_encoder_reconstructions: 10

# Whether or not tSNE plots of latent vectors will be shown at the 3 stages of
# training.
latent_vector_plot: True
